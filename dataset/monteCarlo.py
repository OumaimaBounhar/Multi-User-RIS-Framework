import numpy as np
import pickle
import pandas as pd
import scipy
from tqdm import tqdm
import matplotlib.pyplot as plt
from typing import List
from typing import Tuple
from config.parameters import Parameters
from envs.feedback import Feedback
from envs.channel import Channel
from envs.codebooks import Codebooks

class Dataset_probability:
    """ To compute the probability of p(Y|phi,h), we use Monte Carlo sampling to generate different h_i.
    We either have a predefined list of elements and we use them to compute the probability
    Or we compute a new list every time we update the probability.
    
    We either have access to the real law of the channel, or just to a set of elements measured (from a dataset).
    """
    def __init__(self,
                parameters:Parameters,
                channel:Channel,
                codebooks:Codebooks,
                feedback:Feedback,
                min_representatives:int = 200,
                Noisy_samples:bool=False,
                dataset_samples=[],
                filename = "example"):
        
        self.parameters = parameters
        self.channel = channel
        self.codebooks = codebooks
        self.feedback = feedback
        self.min_representatives = min_representatives
        self.max_samples = 2*min_representatives*parameters.size_codebooks[0]  
        self.Noisy_samples = Noisy_samples
        self.filename = filename
        # If a dataset is available put it here
        self.set_new_MC()
    #     self.save_min_representatives(filename)
    
    # def save_min_representatives(self, filename):
    #     """Saves the value of min_representatives in the given filename."""
        
    #     with open(filename, "w") as f:
    #         f.write(f"min_representatives: {self.min_representatives}\n")           
        
    #     print(f"min_representatives saved in {filename}")
        
    def set_new_MC(self):
        """Generates a set of elements:
        if Noisy_samples=False, No noise in the samples:
        There is at least min_representatives elements for every class (a class is a codeword in the Codebook of communication)
        Except if the number of elements we generate exceeds max_samples"""
        
        size_codebooks = (self.parameters.get_codebook_parameters())[0]
        
        # Initialize storage for representative classes
        List_Representant_Classes = [[[],[]] for k in range(0,size_codebooks[0])]
        
        n_samples = 0
        
        #### Samples are generated by Randomly creating new channels h ####
        print("[INFO] Generating samples")
        
        for snr in self.parameters.snr_values:  # Loop over multiple SNR values
            print(f"[INFO] Generating data for SNR = {snr} dB")
            
            self.parameters.std_noise = math.sqrt(10**(-snr/10))
            self.parameters.set_noise(mean_noise=0, std_noise=self.parameters.std_noise)
            self.parameters.set_SNR(snr)
            
            print(f"  - Set SNR to {self.parameters.SNR}, Std Noise: {self.parameters.std_noise}")
            
            n_representant_class = np.zeros(size_codebooks[0],dtype ="int")
            
            for sample in tqdm(range(self.max_samples//len(self.parameters.snr_values))):
                # if np.all([k >= self.min_representatives for k in n_representant_class]): #To avoid having empty classes
                #     break
                
                self.channel.new_channel() # Generates a new channel
                # print(f"[INFO] SNR values when generating a new channel {self.parameters.SNR} and st noise = {self.parameters.std_noise}")
                
                List_RSE_communication = []
                for n_communications in range(size_codebooks[0]):
                    self.feedback.transmit(n_communications,codebook_used=0)
                    RSE = self.feedback.get_feedback(noise = False) # No noise for the class of the channel
                    List_RSE_communication.append(RSE)
                argmax_RSE_communication = np.argmax(List_RSE_communication)
                
                List_RSE_pilots = []
                for n_pilots in range(size_codebooks[1]):
                    self.feedback.transmit(n_pilots,codebook_used=1)
                    RSE = self.feedback.get_feedback(noise = self.Noisy_samples) # Noise or No noise for the feedback from the channel
                    List_RSE_pilots.append(RSE)
                    
                (List_Representant_Classes[argmax_RSE_communication][0]).append(1) # Probability = 1 for assigned class
                (List_Representant_Classes[argmax_RSE_communication][1]).append(List_RSE_pilots) 
                n_representant_class[argmax_RSE_communication] += 1
                n_samples += 1
            
                if np.all(n_representant_class >= self.min_representatives):
                    print(f" All classes have been filleds. Stopping at SNR={snr}.")
                    break
        
        # Normalize class probabilities
        for k in range(0,size_codebooks[0]):
            List_Representant_Classes[k][0] = np.array(List_Representant_Classes[k][0])/n_samples
        
        self.n_representant_class = n_representant_class
        self.List_Representant_Classes = List_Representant_Classes
        self.save()
        print(f"Sample generation complete: {n_samples} total samples collected.")

    def save(self):
        """Saves everything in a file with a number that is a function of the parameters
        """
        newpath = self.filename
        with open(newpath+"/Dataset.pickle", "wb") as file_:
            pickle.dump(self, file_, -1)
        
    #def get_representant_class(self):
        #return self.n_representant_class
    
    def get_Data(self)->List[Tuple[np.ndarray,List[np.ndarray]]]:
        """Shape of the list:
        List = [[[p(h11),p(h12),...,p(h1d)],[[f(h11,phi_1),...f(h11,phi_N_codewords_pilots)],...,[f(h1d,phi_1),...f(h1d,phi_N_codewords_pilots)]]]_1,
        []_2,......,
        []_N_codewords_communication]"""
        return self.List_Representant_Classes
    
    def get_params_codebook(self):
        """ Used when we saved the dataset somewhere 
        to reuse the same parameters and codebooks as the one used to generate the dataset"""
        return self.parameters, self.codebooks